{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interp\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy\n",
    "from fsl_mrs.utils.preproc.combine import svd_reduce, weightedCombination\n",
    "import scipy.signal.windows as ssw\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from fsl_mrs.utils.plotting import FID2Spec\n",
    "from scipy.interpolate import CubicSpline\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from scipy.signal import butter, filtfilt\n",
    "import fsl_mrs.utils.mrs_io as mrs_io\n",
    "from fsl_mrs.utils.preproc import nifti_mrs_proc as proc\n",
    "from nifti_mrs.create_nmrs import gen_nifti_mrs_hdr_ext\n",
    "import ipywidgets as w\n",
    "from nifti_mrs.nifti_mrs import NIFTI_MRS\n",
    "import nibabel as nib\n",
    "from scipy.interpolate import PchipInterpolator, Akima1DInterpolator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to read the simulated input graidents from POET sequence simulation tool\n",
    "\n",
    "def dsv2timecourse(dsv, truncated):\n",
    "    \"\"\"\n",
    "    Process DSV compressed time-series data.\n",
    "    \n",
    "    :param dsv: Parsed DSV dictionary from dsvRead.\n",
    "    :param truncated: If True, disables sample count validation.1\n",
    "    :return: (t, y) -> Time values and signal values.\n",
    "    \"\"\"\n",
    "    values = np.array(dsv.get('VALUES', []), dtype=float)\n",
    "    if values.size == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    t = np.full(values.shape, np.nan)\n",
    "    y = np.full(values.shape, np.nan)\n",
    "    \n",
    "    t[0] = 1\n",
    "    y[0] = values[0]\n",
    "    \n",
    "    count = 1\n",
    "    idx = 0\n",
    "    this_y_deriv = 0\n",
    "    \n",
    "    while idx < len(values) - 1:\n",
    "        idx += 1\n",
    "        count += 1\n",
    "        last_y_deriv = this_y_deriv\n",
    "        this_y_deriv = values[idx]\n",
    "        \n",
    "        if this_y_deriv == last_y_deriv:\n",
    "            idx += 1\n",
    "            if idx >= len(values):\n",
    "                break\n",
    "            reps = int(values[idx]) + 1\n",
    "        else:\n",
    "            reps = 1\n",
    "        \n",
    "        t[count - 1] = t[count - 2] + reps\n",
    "        y[count - 1] = y[count - 2] + reps * this_y_deriv\n",
    "    \n",
    "    vert_factor = float(dsv['DEFINITIONS'].get('VERTFACTOR', 1))\n",
    "    horidelta = float(dsv['DEFINITIONS'].get('HORIDELTA', 1))\n",
    "    samples = int(dsv['DEFINITIONS'].get('SAMPLES', count))\n",
    "    \n",
    "    y = y[:count] / vert_factor\n",
    "    t = t[:count] * horidelta\n",
    "    \n",
    "    if not truncated and t[-1] != samples:\n",
    "        raise ValueError(\"Sample count mismatch.\")\n",
    "    \n",
    "    return t, y\n",
    "\n",
    "def dsv_read(file_path, plot=True, max_lines=None):\n",
    "    \"\"\"\n",
    "    Reads a Siemens simulator .DSV file and returns the parsed data.\n",
    "    \n",
    "    :param file_path: Path to the .dsv file.\n",
    "    :param plot: If True, plot the data.\n",
    "    :param max_lines: Maximum number of data lines to read.\n",
    "    :return: (t, y, dsv) -> Time values, signal values, and full parsed dictionary.\n",
    "    \"\"\"\n",
    "    dsv = {}\n",
    "    current_section = None\n",
    "    \n",
    "    with open(file_path, 'r', encoding='latin-1') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('[') and line.endswith(']'):\n",
    "                current_section = line[1:-1]\n",
    "                dsv[current_section] = {}\n",
    "            elif '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                dsv[current_section][key.strip()] = value.strip()\n",
    "            elif line and re.match(r'^[0-9.\\-]+$', line):\n",
    "                if isinstance(dsv[current_section], dict):\n",
    "                    # If it's a dictionary, convert it to a list for values\n",
    "                    dsv[current_section] = []\n",
    "                dsv[current_section].append(float(line))\n",
    "                if max_lines and len(dsv[current_section]) >= max_lines:\n",
    "                    break\n",
    "    \n",
    "    t, y = dsv2timecourse(dsv, max_lines is not None)\n",
    "    t= t/1e6\n",
    "    \n",
    "    if plot:\n",
    "        horidelta = float(dsv['DEFINITIONS'].get('HORIDELTA', 1))\n",
    "        plt.figure()\n",
    "        plt.plot(t , y, 'r-')\n",
    "        #plt.xlabel(dsv['DEFINITIONS'].get('HORIUNITNAME', 'Time'))\n",
    "        plt.xlabel('Time/S')\n",
    "        plt.ylabel(dsv['DEFINITIONS'].get('VERTUNITNAME', 'Amplitude'))\n",
    "        plt.title(dsv['DEFINITIONS'].get('TITLE', 'DSV Data'))\n",
    "        plt.show()\n",
    "    \n",
    "    return t, y, dsv\n",
    "\n",
    "\n",
    "#Resample gradients to the dwell time of the readout for ease of FT in later steps\n",
    "\n",
    "def resample(t, y): \n",
    "    timeinterval = 5e-6\n",
    "    time = np.arange(0, max(t)+timeinterval/2, timeinterval)\n",
    "\n",
    "    f = interp.interp1d(t, y, kind='linear', fill_value=\"extrapolate\")  # linear interpolation\n",
    "    new_y = f(time)\n",
    "\n",
    "\n",
    "    time = time[0:]\n",
    "    new_y = new_y[0:]\n",
    "\n",
    "\n",
    "    return time, new_y\n",
    "\n",
    "#Function for time-alignment of the FID and phase error after integration\n",
    "\n",
    "def shift_half_index_spline(array, shift):\n",
    "    N = len(array)\n",
    "    x = np.arange(N)\n",
    "    spline = CubicSpline(x, array, bc_type='natural')\n",
    "    x_shifted = x +shift   # Shift by half an index\n",
    "    return spline(x_shifted)  # Evaluate shifted function\n",
    "\n",
    "#Sinc function filter to account for the finite sampling in the ADC readout \n",
    "\n",
    "def custom_sinc_function(t=5e-6, length=1000):\n",
    "\n",
    "    # Create frequency vector\n",
    "    f = np.fft.fftshift(np.fft.fftfreq(length, t))\n",
    "\n",
    "    # Compute sinc(tf) safely\n",
    "    x = t * f\n",
    "    y = np.sinc(x)  # np.sinc(x) = sin(pi*x)/(pi*x), so scale appropriately\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Path to the directory \n",
    "NOTEBOOK_DIR = Path().resolve()\n",
    "print(NOTEBOOK_DIR)\n",
    "part = '004'\n",
    "\n",
    "#Load in preprocessed data following spec2nii (https://github.com/wtclarke/spec2nii) of the twix files and mPress_preproc of those\n",
    "\n",
    "final_sup2  = mrs_io.read_FID(rf'{NOTEBOOK_DIR}/Data_for_correction/mPress_preproc/{part}/sup_preproc.nii.gz')\n",
    "unsupp_data4 = mrs_io.read_FID(rf'{NOTEBOOK_DIR}/Data_for_correction/mPress_preproc/{part}/unsup_preproc.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Truncation used in preprocessing\n",
    "N=4\n",
    "N1=4\n",
    "\n",
    "#Extract the on and off data for both sup and unsup into numpy arrays\n",
    "dataWS = np.conj(final_sup2[0,0,0,:,0])\n",
    "dataWS1 = np.conj(final_sup2[0,0,0,:,1])\n",
    "dataNoWS = np.conj(unsupp_data4[0,0,0,:,0])\n",
    "dataNoWS1 = np.conj(unsupp_data4[0,0,0,:,1])\n",
    "\n",
    "freq = np.fft.fftshift(np.fft.fftfreq(4124, d=1/8000))\n",
    "\n",
    "#Time step based off the bandwidth\n",
    "#timeNoWS are the timepoints of the readout period, readout starts at 0.98301 seconds for this sequence \n",
    "\n",
    "time_step = 1/(4000*2)\n",
    "timeNoWS = np.arange(N*time_step + 0.98301, (len(dataWS)+N)*time_step+0.98301 - time_step/2, time_step)\n",
    "freqNoWS = np.fft.fftshift(np.fft.fftfreq(len(dataNoWS), d=time_step))\n",
    "freqWS =np.fft.fftshift(np.fft.fftfreq(len(dataWS), d=time_step))\n",
    "\n",
    "#Convert to ppm\n",
    "freqNoWS=freqNoWS/(123.224196)\n",
    "freqWS=freqWS/(123.224196)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in gradients and resample to the dwell time \n",
    "\n",
    "file_path = rf'{NOTEBOOK_DIR}/Data_for_correction/gradients_mPress/SimulationProtocol_ADC.dsv'\n",
    "t, y, dsv = dsv_read(file_path, plot=False, max_lines=10000)\n",
    "time, new_y = resample(t, y)\n",
    "\n",
    "max_index = int(max(time)/5e-6)\n",
    "\n",
    "\n",
    "file_path = rf'{NOTEBOOK_DIR}/Data_for_correction/gradients_mPress/SimulationProtocol_GRX.dsv'\n",
    "t, y, dsv = dsv_read(file_path, plot=False, max_lines=10000)\n",
    "time, gradX = resample(t, y)\n",
    "\n",
    "file_path = rf'{NOTEBOOK_DIR}/Data_for_correction/gradients_mPress/SimulationProtocol_GRY.dsv'\n",
    "t, y, dsv = dsv_read(file_path, plot=False, max_lines=10000)\n",
    "time, gradY = resample(t, y)\n",
    "\n",
    "file_path = rf'{NOTEBOOK_DIR}/Data_for_correction/gradients_mPress/SimulationProtocol_GRZ.dsv'\n",
    "t, y, dsv = dsv_read(file_path, plot=False, max_lines=10000)\n",
    "time, gradZ = resample(t, y)\n",
    "\n",
    "#Use only first TR\n",
    "\n",
    "new_y=new_y[683000:983000]\n",
    "gradX = gradX[683000:983000]\n",
    "gradY = gradY[683000:983000]\n",
    "gradZ = gradZ[683000:983000]\n",
    "\n",
    "#Zero pad end to avoid cyclic artefacts from the Fourier Transform in next step\n",
    "#Specific number is chosen so the length is an interger mutiple of the number of points in the GIRF, 39993, so interpolation works smoothly\n",
    "\n",
    "gradX = np.pad(gradX, (0,241976), mode='constant')\n",
    "gradY = np.pad(gradY, (0,241976), mode='constant')\n",
    "gradZ = np.pad(gradZ, (0,241976), mode='constant')\n",
    "\n",
    "t = np.arange(0, len(gradX)*5e-6, 5e-6)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, gradX)\n",
    "plt.plot(t, gradY)\n",
    "plt.plot(t, gradZ)\n",
    "#plt.plot(time, new_y)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutiply the Input gradients by the GIRF in the frequency domain and IFT back to the time domain\n",
    "\n",
    "#5Hz resolution on GIRF B0 and self terms \n",
    "P = 39993\n",
    "#Order of Spherical harmonics\n",
    "order = 1\n",
    "\n",
    "def get_predicted_grad(input, dir, order):\n",
    "    gradInputFT = np.fft.fftshift(np.fft.fft(input))\n",
    "    #filter to reduce high frequency noise\n",
    "    filter = ssw.tukey(len(gradInputFT), alpha =0.93)**25\n",
    "\n",
    "    default_file_path = rf'{NOTEBOOK_DIR}\\GIRF_measurements\\Results39993/SphericalHarmonics_{dir.upper()}_{order}.npz'\n",
    "    alt_P =19999\n",
    "    #10Hz reolusiton for cross terms\n",
    "    alt_file_path = rf'{NOTEBOOK_DIR}\\GIRF_measurements\\Results19999/SphericalHarmonics_{dir.upper()}_{order}.npz'\n",
    "\n",
    "    grad_pred = []\n",
    "    for i in range(4):\n",
    "        # decide whether this iteration should use the alternate P/file\n",
    "        use_alt = False\n",
    "        if dir == 'y' and (i == 1 or i == 3):\n",
    "            use_alt = True\n",
    "        if dir == 'x' and (i == 2 or i == 3):\n",
    "            use_alt = True\n",
    "        if dir == 'z' and (i == 1 or i == 2):\n",
    "            use_alt = True\n",
    "\n",
    "        # choose file path and P for this iteration\n",
    "        if use_alt:\n",
    "            file_path = alt_file_path\n",
    "            current_P = alt_P\n",
    "        else:\n",
    "            file_path = default_file_path\n",
    "            current_P = P\n",
    "\n",
    "        npz_data = np.load(file_path)\n",
    "        GIRF_FT = npz_data.get('GIRF_FT', None)\n",
    "        GIRF_FT = np.mean(GIRF_FT, axis=2)\n",
    "        \n",
    "        #Dwell time filter\n",
    "        customsinc = custom_sinc_function(5e-6, current_P)\n",
    "        GIRF_FT1 = GIRF_FT[i,:]/customsinc\n",
    "        f = np.fft.fftshift(np.fft.fftfreq(current_P, 5e-6))\n",
    "\n",
    "\n",
    "        x_original = np.linspace(0, 1, current_P)\n",
    "        x_target   = np.linspace(0, 1, len(gradInputFT))\n",
    "\n",
    "        #Interpolate GIRF to same number of points as input gradients for mutiplication\n",
    "        # If the spectrum is complex, interpolate real & imag separately:\n",
    "        p_real  = Akima1DInterpolator(x_original, np.real(GIRF_FT1))\n",
    "        p_imag  = Akima1DInterpolator(x_original, np.imag(GIRF_FT1))\n",
    "        girf_interpolated = p_real(x_target) + 1j*p_imag(x_target)\n",
    "\n",
    "        #Separate out cross terms\n",
    "        if dir =='y' and (i == 1 or i == 3) :\n",
    "            interp_func = interp1d(x_original, GIRF_FT1, kind='linear', fill_value=\"extrapolate\")\n",
    "            girf_interpolated = interp_func(x_target)\n",
    "\n",
    "        if dir =='x' and (i == 2 or i == 3) :\n",
    "            interp_func = interp1d(x_original, GIRF_FT1, kind='linear', fill_value=\"extrapolate\")\n",
    "            girf_interpolated = interp_func(x_target)\n",
    "\n",
    "        if dir =='z' and (i == 1 or i == 2) :\n",
    "            interp_func = interp1d(x_original, GIRF_FT1, kind='linear', fill_value=\"extrapolate\")\n",
    "            girf_interpolated = interp_func(x_target)\n",
    "\n",
    "        #Mutiplicaton in frequency domain, and by filter to reduce high frequency noise \n",
    "        gradOutputFTPred = girf_interpolated* gradInputFT *filter\n",
    "        gradOutputPred = np.fft.ifft(np.fft.ifftshift(gradOutputFTPred))\n",
    "        grad_pred.append(gradOutputPred)\n",
    "\n",
    "    #Return predicted gradient field\n",
    "    return np.asarray(grad_pred)\n",
    "\n",
    "#Get predicted field for x,y,z input gradient directions\n",
    "gradpredX = get_predicted_grad(gradX, 'x', order)\n",
    "gradpredY = get_predicted_grad(gradY, 'y', order)\n",
    "gradpredZ = get_predicted_grad(gradZ, 'z', order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish readout time for the time-integration during the readout period\n",
    "\n",
    "time_step = 1/(4000*2)\n",
    "\n",
    "timeNoWS = np.arange(N*time_step + 0.98301, (len(dataNoWS)+N)*time_step+0.98301 - time_step/2, time_step)\n",
    "\n",
    "start_time = np.round(timeNoWS[0],8)\n",
    "end_time = np.round(timeNoWS[-1], 8)\n",
    "\n",
    "interval = np.arange(start_time, end_time, 5e-6)\n",
    "\n",
    "start_index = int(start_time/5e-6)\n",
    "end_index = start_index + len(interval)\n",
    "\n",
    "def ppm_formatter(x, pos):\n",
    "    return f'{4.65 - x:.2f}'\n",
    "\n",
    "gamma = 42.576e3*2*np.pi\n",
    "\n",
    "# Define the function for dynamic plotting\n",
    "current_xlim = None\n",
    "current_ylim = None\n",
    "\n",
    "#Filter to help with downsampling \n",
    "def lowpass_filter(data, orig_rate, target_rate, cutoff_factor=0.8):\n",
    "    nyq = 0.5 * orig_rate\n",
    "    cutoff = 0.5 * target_rate * cutoff_factor  # Slightly below Nyquist\n",
    "    b, a = butter(4, cutoff / nyq, btype='low')\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def update_plot(sox, soy, soz, shift, exp_shift, exp_shift1):\n",
    "\n",
    "    global current_xlim, current_ylim\n",
    "    r2 = sox**2 + soy**2 + soz**2\n",
    "    offsets = [-1, sox, soy, soz, \n",
    "               sox * soy, soz * soy, 3 * soz**2 - r2, sox * soz, sox**2 - soy**2,  \n",
    "               soy * (3 * sox**2 - soy**2), sox * soy * soz, soy * (5 * soz**2 - r2), 5 * soz**3 - 3 * soz * r2, sox * (5 * soz**2 - r2), (sox**2 - soy**2) * soz, sox * (sox**2 - 3 * soy**2)]\n",
    "    cor = []\n",
    "\n",
    "    #Perform integration for fields during the readout period\n",
    "    #Mutiply by the spherical harmonic component evaluated at the voxel centre for phase error\n",
    "    for i in range(4):\n",
    "        if i ==0:\n",
    "            integralX = cumulative_trapezoid(gradpredX[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "            integralY = cumulative_trapezoid(gradpredY[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "            integralZ = cumulative_trapezoid(gradpredZ[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "        else: \n",
    "            integralX = cumulative_trapezoid(gradpredX[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "            integralY = cumulative_trapezoid(gradpredY[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "            integralZ = cumulative_trapezoid(gradpredZ[i, start_index:end_index], interval, initial=0)*offsets[i]\n",
    "        cor.append(integralX)\n",
    "        cor.append(integralY)\n",
    "        cor.append(integralZ)\n",
    "\n",
    "    \n",
    "    cor = np.array(cor)  # Convert to NumPy array if it's not already\n",
    "\n",
    "    #Calculate total phase error\n",
    "    cortotal = np.sum(cor, axis =0)* gamma\n",
    "    phase = np.unwrap(np.angle(dataNoWS))\n",
    "    phase1 = np.unwrap(np.angle(dataNoWS1))\n",
    "    \n",
    "    #Perform downsamplign to mathc the original FID\n",
    "    # Before interpolation:\n",
    "    original_dt = 5e-6       \n",
    "    target_dt = time_step     \n",
    "\n",
    "    # Convert time steps to sampling rates\n",
    "    target_rate = 1 / target_dt\n",
    "    orig_rate = 1 / original_dt\n",
    "\n",
    "    cortotal_filtered = lowpass_filter(cortotal, orig_rate, target_rate)\n",
    "\n",
    "    cordown = scipy.signal.resample(cortotal_filtered, len(dataNoWS))\n",
    "\n",
    "    cordown = shift_half_index_spline(cordown, shift)\n",
    "    # Subtract to get residual \n",
    "    # Perfromed for both the on and off MEGA-PRESS acquisitions\n",
    "    phasecor = phase - cordown\n",
    "    phasecor1 = phase1 - cordown\n",
    "\n",
    "\n",
    "    corrected = np.abs(dataNoWS) * np.exp(1j * phasecor)\n",
    "    corrected1 = np.abs(dataNoWS1) * np.exp(1j * phasecor1) \n",
    "\n",
    "    corrected_plot = corrected* np.exp(1j * (exp_shift ))\n",
    "    corrected_plot1 =  corrected1* np.exp(1j * (exp_shift1 ))\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot((freqWS), -FID2Spec(dataWS), label='Water Suppressed')\n",
    "    ax.plot((freqNoWS), np.roll(FID2Spec(corrected_plot),0), label='GIRF Corrected Non-Water Suppressed')\n",
    "    ax.plot((freqNoWS), np.roll(FID2Spec(corrected_plot1),0), label='GIRF Corrected Non-Water Suppressed')\n",
    "    #ax.plot((freqNoWS), np.roll(FID2Spec(dataNoWS*np.exp(1j*exp_shift)),-1), label='Uncorrected Non-Water Suppressed')\n",
    "\n",
    "\n",
    "    ax.set_title(\"in vivo, V1\")\n",
    "\n",
    "\n",
    "    ax.legend(fontsize='small', loc = 'upper right')\n",
    "    ax.set_ylabel('Signal [AU]')\n",
    "    ax.set_xlabel('Chemical Shift (ppm)')\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(ppm_formatter))\n",
    "\n",
    "    # Restore previous zoom if it exists\n",
    "    if current_xlim is None:\n",
    "        current_xlim = (-5, 5)\n",
    "        ax.set_xlim(current_xlim)\n",
    "    else:\n",
    "        ax.set_xlim(current_xlim)\n",
    "\n",
    "    if current_ylim is None:\n",
    "        current_ylim = (-0.00002, 0.00006)\n",
    "        ax.set_ylim(current_ylim)\n",
    "    else:\n",
    "        ax.set_ylim(current_ylim)\n",
    "\n",
    "    # Hook up event to capture new zoom\n",
    "    def on_xlim_changed(event_ax):\n",
    "        global current_xlim\n",
    "        current_xlim = event_ax.get_xlim()\n",
    "        print(current_xlim)\n",
    "\n",
    "    def on_ylim_changed(event_ax):\n",
    "        global current_ylim\n",
    "        current_ylim = event_ax.get_ylim()\n",
    "\n",
    "    # Register callbacks\n",
    "    ax.callbacks.connect('xlim_changed', on_xlim_changed)\n",
    "    ax.callbacks.connect('ylim_changed', on_ylim_changed)\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return corrected_plot, corrected_plot1\n",
    "\n",
    "last_corrected = None  # will hold the returned array\n",
    "\n",
    "def _wrap_update_plot(sox, soy, soz, shift, exp_shift, exp_shift1):\n",
    "    global last_corrected, last_corrected1\n",
    "    last_corrected, last_corrected1 = update_plot(sox, soy, soz, shift, exp_shift, exp_shift1)\n",
    "    # return value is ignored by interact; we keep it in last_corrected\n",
    "\n",
    "\n",
    "#Input the voxel location here in metres\n",
    "# sox: L-R direction (left is negative)\n",
    "# soy: A-P direction (A is negative)\n",
    "# soz: F-H direction (F is negative)\n",
    "# shift is for time-alignment of FID and phase correction \n",
    "# exp_shift is a zeroth order phase correction\n",
    "\n",
    "w.interact(\n",
    "    _wrap_update_plot,\n",
    "    sox=w.FloatSlider(min=-0.045, max=0.045, step=0., value=0.0031),\n",
    "    soy=w.FloatSlider(min=-0.03,  max=0.06,  step=0.001, value=0.0559),\n",
    "    soz=w.FloatSlider(min=-0.06,  max=0.06,  step=0.001, value=0.0001),\n",
    "    shift=w.FloatSlider(min=-0.5, max=1,    step=0.01,  value=0.5),\n",
    "    exp_shift=w.FloatSlider(min=2.8,  max=3.6, step=0.00005, value=3.36),\n",
    "    exp_shift1=w.FloatSlider(min=2.8, max=3.6, step=0.00005, value=3.37)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform spectral editing if wanted\n",
    "diff = (proc.subtract(proc.align(final_sup2, 'DIM_EDIT', ppmlim=(2.8, 4), figure=False ),dim='DIM_EDIT', figure=False))\n",
    "diff = proc.shift_to_reference(diff, 2.01, (1.9,2.1))\n",
    "diff= proc.apply_fixed_phase(proc.phase_correct(diff, (1.9,2.1)), 180)\n",
    "\n",
    "#Extract just the off data\n",
    "off_sup = diff.copy()\n",
    "off_sup[:] = final_sup2[:,:,:,:,0]\n",
    "\n",
    "off_sup = proc.phase_correct(off_sup, (1.9, 2.1))\n",
    "\n",
    "off_unsup = diff.copy()\n",
    "off_unsup[:] = np.conj(last_corrected)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "_ = off_sup.plot(ppmlim= (0,4.2))\n",
    "_ = off_unsup.plot(ppmlim=(0,4.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Optionally save out the water suppressed, and the GIRF-corrected non-water suppressed data\n",
    "\n",
    "#off_sup.save(rf'{NOTEBOOK_DIR}/Data_for_fitting/mPress/{part}/off_sup.nii.gz')\n",
    "#off_unsup.save(rf'{NOTEBOOK_DIR}/Data_for_fitting/mPress/{part}/off_unsup.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsl_mrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
